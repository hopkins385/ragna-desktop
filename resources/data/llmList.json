[
  {
    "id": "01HNQKEAKBGQ7Q8HBVMXFZJW1Q",
    "title": "Meta - Llama 3 8K Instruct",
    "details": {
      "description": "The Llama 3 instruction tuned models are optimized for dialogue use cases and outperform many of the available open source chat models on common industry benchmarks.",
      "quant": "8bit",
      "format": "gguf",
      "model_paramaters": 80,
      "prompt_template": "llama3",
      "repo_link": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
      "license": "llama3",
      "languages": ["en"]
    },
    "hf_params": {
      "owner": "Svensonai",
      "repo": "Meta-Llama-3-8B-Instruct-gguf",
      "file": "Meta-Llama-3-8B-Instruct_q8_0.gguf",
      "file_size": 854
    }
  },
  {
    "id": "01J0DW1PKEH3HK15Y02DJXZHP4",
    "title": "Microsoft - Phi 3 Mini 4K Instruct",
    "details": {
      "description": "The Phi-3-Mini-4K-Instruct is a 3.8B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets. When assessed against benchmarks testing common sense, language understanding, math, code, long context and logical reasoning, Phi-3 Mini-4K-Instruct showcased a robust and state-of-the-art performance among models with less than 13 billion parameters.",
      "quant": "BF16",
      "format": "gguf",
      "model_paramaters": 38,
      "prompt_template": "phi3?",
      "repo_link": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct",
      "license": "mit",
      "languages": ["en"]
    },
    "hf_params": {
      "owner": "microsoft",
      "repo": "Phi-3-mini-4k-instruct-gguf",
      "file": "Phi-3-mini-4k-instruct-fp16.gguf",
      "file_size": 764
    }
  },
  {
    "id": "01HNQKVAKBGQ7Q8HBVMXFZJW1Q",
    "title": "DiscoResearch - Llama3-DiscoLeo-Instruct 8K",
    "details": {
      "description": "Llama3-DiscoLeo-Instruct 8B is an instruction tuned version of our Llama3-German-8B. The base model was derived from Meta's Llama3-8B through continuous pretraining on 65 billion high-quality German tokens, similar to previous LeoLM or Occiglot models. We finetuned this checkpoint on the German Instruction dataset",
      "quant": "8bit",
      "format": "gguf",
      "model_paramaters": 80,
      "prompt_template": "llama3",
      "repo_link": "https://huggingface.co/DiscoResearch/Llama3-DiscoLeo-Instruct-8B-v0.1",
      "license": "llama3",
      "languages": ["de", "en"]
    },
    "hf_params": {
      "owner": "Svensonai",
      "repo": "Llama3-DiscoLeo-Instruct-8B-v0.1-GGUF",
      "file": "Llama3-DiscoLeo-Instruct-8B-v0.1_q8_0.gguf",
      "file_size": 854
    }
  },
  {
    "id": "01HNQKEAKBGQ7Q8HBVMXFZJW1T",
    "title": "Teknium - OpenHermes 2.5",
    "details": {
      "description": "The OpenHermes Model is a state of the art Mistral Fine-tune, a continuation of OpenHermes 2 model, which was trained on additional code datasets.",
      "quant": "8bit",
      "format": "gguf",
      "model_paramaters": 72,
      "prompt_template": "chatml",
      "repo_link": "https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B",
      "license": "Apache-2.0",
      "languages": ["en"]
    },
    "hf_params": {
      "owner": "TheBloke",
      "repo": "OpenHermes-2.5-Mistral-7B-GGUF",
      "file": "openhermes-2.5-mistral-7b.Q8_0.gguf",
      "file_size": 770
    }
  },
  {
    "id": "01HNQKEBKBGQ7Q8HBVMXFZJW5T",
    "title": "HuggingFaceH4 - Zephyr 7B β",
    "details": {
      "description": "Zephyr is a series of language models that are trained to act as helpful assistants. Zephyr-7B-β is the second model in the series, and is a fine-tuned version of mistralai/Mistral-7B-v0.1 that was trained on on a mix of publicly available, synthetic datasets.",
      "quant": "8bit",
      "format": "gguf",
      "model_paramaters": 72,
      "prompt_template": "Zephyr",
      "repo_link": "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta",
      "license": "MIT",
      "languages": ["en"]
    },
    "hf_params": {
      "owner": "TheBloke",
      "repo": "zephyr-7B-beta-GGUF",
      "file": "zephyr-7b-beta.Q8_0.gguf",
      "file_size": 770
    }
  },
  {
    "id": "01HNQKEBKBGQ7Q8HBVMXFZJW3T",
    "title": "OpenOrca - MistralOrca",
    "details": {
      "description": "A fully open model with class-breaking performance. This release is trained on a curated filtered subset of most of our GPT-4 augmented data.",
      "quant": "8bit",
      "format": "gguf",
      "model_paramaters": 72,
      "prompt_template": "chatml",
      "repo_link": "https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca",
      "license": "Apache-2.0",
      "languages": ["en"]
    },
    "hf_params": {
      "owner": "TheBloke",
      "repo": "Mistral-7B-OpenOrca-GGUF",
      "file": "mistral-7b-openorca.Q8_0.gguf",
      "file_size": 770
    }
  },
  {
    "id": "02HNQKEBKBGQ7Q8HBVMXFZJW3T",
    "title": "Microsoft - Phi 2",
    "details": {
      "description": "Phi-2 is a Transformer with 2.7 billion parameters. It was trained using the same data sources as Phi-1.5, augmented with a new data source that consists of various NLP synthetic texts and filtered websites (for safety and educational value).",
      "quant": "8bit",
      "format": "gguf",
      "model_paramaters": 27,
      "prompt_template": "Phi",
      "repo_link": "https://huggingface.co/microsoft/phi-2",
      "license": "MIT",
      "languages": ["en"]
    },
    "hf_params": {
      "owner": "TheBloke",
      "repo": "phi-2-GGUF",
      "file": "phi-2.Q8_0.gguf",
      "file_size": 296
    }
  }
]
